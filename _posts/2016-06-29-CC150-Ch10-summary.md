---
layout: post
title: CC150 Chapter 10---Scalability and Memory Limits
date: 2016-06-29
categories: blog
tags: [study]

---

# Step-By-Step方法

面试官测试的是分解问题，用已知知识解决问题的能力

### Step1:假设

假设内存无限制，数据都读入一个机器，有什么解决问题的方法？这个方法是解决问题的基基础。

### Step2:现实

回到现实，机器一次能读多少数据？把数据拆分有什么问题？常见的问题是如何拆分数据，如何寻找数据。

### Step3:解决问题

最后思考如何解决第二步中的现实问题，通常可以基于第一步，一步一步解决问题。我们的目标不是设计一个几百万的系统，而是展示我们分析问题，解决问题的能力。

# 基本知识

### 典型系统

尽管有超级计算机，但大多数网络公司使用大型互联的系统。

我们需要了解下面这些基本信息（仅举例）

<table>
  <tr>
    <th>组件</th>
    <th>常见容量</th>
  </tr>
  <tr>
  	<td>硬盘</td>
  	<td>4TB</td>
  </tr>
  <tr>
  	<td>内存</td>
  	<td>16GB</td>
  </tr>
  <tr>
  	<td>网络延迟</td>
  	<td>40ms</td>
  </tr>
</table>

### 拆分数据

数据需要拆分存放在不同分布式系统中的不同机器中，如何决定哪些数据放在哪台机器上呢？

* **顺序** 根据数据的顺序，新数据直到当前机器存满才增加另一台机器。优点是机器少，缺点是查找表（lookup table）复杂。
* **哈希值** 根据数据的哈希值存储。对key值取hash，然后mod机器的数量，存入对应的机器。优点是不需要查找表，每台机器都知道如何找数据，缺点是可能一台机器超过容量，我们需要将数据存到别的机器上，导致机器的树状连接。
* **数据意义** 根据哈希十分随意，数据意义和机器之间没有对应关系，导致延迟增加。比如对于社交网络，我们可以按照国家进行朋友关系的存储。
* **随意** 数据被随意分割，我们实现查找表进行数据查询，需要庞大的查找表，但是简化系统设计，更容易做load balance。

# 案例：找出所有含有指定words list的document

**描述**：上百万份document，给出一个list of words，找出所有包含这些words的document。words不需要按指定顺序出现，但必须完整，比如"book"不匹配"bookkeeper"。

首先关键是弄清楚这是一次性操作，还是需要重复多次的操作，即我们是否接受多余的预处理。

### Step1

首先假设没有上百万份document，只有几份，我们应该怎么做呢？

一个方法是对每个document预处理，用哈希表，word作为key，document的链表作为value。

"books" -> {doc2, doc3, doc6, doc8}  
"many" -> {doc1, doc3, doc7, doc8, doc9}

当查找由books和many组成的list，取交集即可。

### Step2

现实的问题是我们有上百万份document，我们需要把它们分布存储在许多机器上，这将带来问题，我们甚至可能无法把哈希表存入一个机器。

1. 我们如何拆分哈希表？我们可以根据关键字拆分，一台机器保存一个关键字的所有document list；我们也可以根据document分，一台机器保存映射到某些document的关键字。
2. 一旦我们决定了拆分数据的方法，我们需要在一台机器上处理document，并把结果存到另一台机器，工作过程是怎样的？（如果我们根据document拆分哈希表则不需要这步）
3. 我们如何设计查找表？

### Step3

